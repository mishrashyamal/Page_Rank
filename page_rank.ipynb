{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gram-Schmidt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "\n",
    "tol = 1e-14 # That's 1×10⁻¹⁴ = 0.00000000000001\n",
    "\n",
    "# Our first function will perform the Gram-Schmidt procedure for 4 basis vectors.\n",
    "# Go through the vectors one at a time and set them to be orthogonal\n",
    "# to all the vectors that came before it. \n",
    "# Normalising or making it unit vector.\n",
    "\n",
    "def orthoBasis4(A) :\n",
    "    B = np.array(A,dtype=np.float_) \n",
    "    # First column is easy.. just normalise it. I.e. divide by its norm.\n",
    "    B[:, 0] = B[:, 0] / la.norm(B[:, 0])\n",
    "    # For second column, we need to subtract the projection of the first vector on the second\n",
    "    B[:, 1] = B[:, 1] - B[:, 1] @ B[:, 0] * B[:, 0]\n",
    "    # Note that if it is non zero, then B[:, 1] is linearly independant of B[:, 0]\n",
    "    # If this is the case, we can normalise it. Otherwise we'll set that vector to zero.\n",
    "    if la.norm(B[:, 1]) > tol :\n",
    "        B[:, 1] = B[:, 1] / la.norm(B[:, 1])\n",
    "    else :\n",
    "        B[:, 1] = np.zeros_like(B[:, 1]) #zeros_like is similar to np.zeros but uses the dimension of input array\n",
    "    # Now we need to repeat the process for remaining columns\n",
    "    # Insert your code here. you can do it in 2 lines or one line\n",
    "    # Again we'll need to normalise our new vector.\n",
    "    # Repeat what we had done earlier\n",
    "    \n",
    "        B[:, 2] = B[:, 2] - B[:, 2] @ B[:, 0] * B[:, 0] - B[:, 2] @ B[:, 1] * B[:, 1]\n",
    "        B[:, 2] = B[:, 2] / la.norm(B[:, 2]) if la.norm(B[:, 2]) > tol else np.zeros_like(B[:, 2])\n",
    "    \n",
    "    \n",
    "    # Finally, column three:\n",
    "    # Insert your code here. either one line or three lines\n",
    "    \n",
    "        B[:, 3] = B[:, 3] - B[:, 3] @ B[:, 0] * B[:, 0] - B[:, 3] @ B[:, 1] * B[:, 1] - B[:, 3] @ B[:, 2] * B[:, 2]\n",
    "        B[:, 3] = B[:, 3] / la.norm(B[:, 3]) if la.norm(B[:, 3]) > tol else np.zeros_like(B[:, 3])\n",
    "    \n",
    "    # Now normalise if possible\n",
    "    \n",
    "    # Finally, we return the result:\n",
    "    return B\n",
    "\n",
    "# Exploit the repetition in the above code to generalize the function for any given matrix\n",
    "def orthoBasis(A) :\n",
    "    B = np.array(A, dtype=np.float_) \n",
    "    # Loop over all vectors, starting with zero, label them with i\n",
    "    for i in range(B.shape[1]) :\n",
    "        # Inside that loop, loop over all previous vectors, j, to subtract.\n",
    "        for j in range(i) :\n",
    "            # Complete the code\n",
    "            \n",
    "             B[:, i] = B[:, i] - B[:, i] @ B[:, j] * B[:, j]\n",
    "        if la.norm(B[:, i]) > tol :\n",
    "            B[:, i] = B[:, i] / la.norm(B[:, i])\n",
    "        else :\n",
    "            B[:, i] = np.zeros_like(B[:, i])\n",
    "            \n",
    "        # Next insert code to do the normalisation test for B[:, i]\n",
    "        \n",
    "        B[:, i] = B[:, i] - B[:, i] @ B[:, j] * B[:, j]\n",
    "        B[:, i] = B[:, i] / la.norm(B[:, i]) if la.norm(B[:, i]) > tol else np.zeros_like(B[:, i])\n",
    "            \n",
    "    # Finally, we return the result:\n",
    "    \n",
    "    return B\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#sanity check. You should get the following solution if you run this\n",
    "V = np.array([[1,0,2,6],\n",
    "              [0,1,8,2],\n",
    "              [2,8,3,1],\n",
    "              [1,6,2,3]], dtype=np.float_)\n",
    "orthoBasis4(V)\n",
    "\n",
    "array([[ 0.40824829, -0.1814885 ,  0.04982278,  0.89325973],\n",
    "       [ 0.        ,  0.1088931 ,  0.99349591, -0.03328918],\n",
    "       [ 0.81649658,  0.50816781, -0.06462163, -0.26631346],\n",
    "       [ 0.40824829, -0.83484711,  0.07942048, -0.36063281]])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#sanity check\n",
    "orthoBasis(V)\n",
    "\n",
    "array([[ 0.40824829, -0.1814885 ,  0.04982278,  0.89325973],\n",
    "       [ 0.        ,  0.1088931 ,  0.99349591, -0.03328918],\n",
    "       [ 0.81649658,  0.50816781, -0.06462163, -0.26631346],\n",
    "       [ 0.40824829, -0.83484711,  0.07942048, -0.36063281]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PageRank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PageRank as a linear algebra problem\n",
    "Let's imagine a micro-internet, with just 6 websites \n",
    "Each website links to some of the others, and this forms a network as shown,\n",
    "\n",
    "![A Micro-Internet](internet_1.png \"A Micro-Internet\")\n",
    "\n",
    "\n",
    "Imagine 100s of a person P on our micro-internet, each viewing a single website at a time.\n",
    "Each minute P follow a link on their website to another site on the micro-internet.\n",
    "After a while, the websites that are most linked to will have more Ps visiting them, and in the long run, each minute for every P that leaves a website, another will enter keeping the total numbers of Ps on each website constant.\n",
    "The PageRank is simply the ranking of websites by how many Ps they have on them at the end of this process.\n",
    "\n",
    "We represent the number of Ps on each website with the vector,\n",
    "$$\\mathbf{r} = \\begin{bmatrix} r_A \\\\ r_B \\\\ r_C \\\\ r_D \\\\ r_E \\\\ r_F \\end{bmatrix}$$\n",
    "And say that the number of Ps on each website in minute $i+1$ is related to those at minute $i$ by the matrix transformation\n",
    "\n",
    "$$ \\mathbf{r}^{(i+1)} = L \\,\\mathbf{r}^{(i)}$$\n",
    "with the matrix $L$ taking the form,\n",
    "$$ L = \\begin{bmatrix}\n",
    "L_{A→A} & L_{B→A} & L_{C→A} & L_{D→A} & L_{E→A} & L_{F→A} \\\\\n",
    "L_{A→B} & L_{B→B} & L_{C→B} & L_{D→B} & L_{E→B} & L_{F→B} \\\\\n",
    "L_{A→C} & L_{B→C} & L_{C→C} & L_{D→C} & L_{E→C} & L_{F→C} \\\\\n",
    "L_{A→D} & L_{B→D} & L_{C→D} & L_{D→D} & L_{E→D} & L_{F→D} \\\\\n",
    "L_{A→E} & L_{B→E} & L_{C→E} & L_{D→E} & L_{E→E} & L_{F→E} \\\\\n",
    "L_{A→F} & L_{B→F} & L_{C→F} & L_{D→F} & L_{E→F} & L_{F→F} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "where the columns represent the probability of leaving a website for any other website, and sum to one.\n",
    "The rows determine how likely you are to enter a website from any other, though these need not add to one.\n",
    "The long time behaviour of this system is when $ \\mathbf{r}^{(i+1)} = \\mathbf{r}^{(i)}$, so we'll drop the superscripts here, and that allows us to write,\n",
    "$$ L \\,\\mathbf{r} = \\mathbf{r}$$\n",
    "\n",
    "which is an eigenvalue equation for the matrix $L$, with eigenvalue 1 (this is guaranteed by the probabalistic structure of the matrix $L$).\n",
    "\n",
    "Complete the matrix $L$ below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the ??? here with the probability of clicking a link to each website.\n",
    "L = np.array([[0,   1/2, 1/3,  0,  0,      0],\n",
    "              [1/3,  0,   0,    0,  1/2,    0],   \n",
    "              [1/3,  1/2, 0,    1,  0,    1/2],\n",
    "              [1/3,  0,   1/3,  0,  1/2,  1/2],\n",
    "              [0,    0,   0,    0,  0,      0],\n",
    "              [0,    0,   1/3,  0,  0,      0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.        ,  5.33333333, 40.        , 25.33333333,  0.        ,\n",
       "       13.33333333])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eVals, eVecs = la.eig(L) # Gets the eigenvalues and vectors\n",
    "order = np.absolute(eVals).argsort()[::-1] # Orders them by their eigenvalues\n",
    "eVals = eVals[order]\n",
    "eVecs = eVecs[:,order]\n",
    "\n",
    "r = eVecs[:, 0] # Sets r to be the principal eigenvector\n",
    "100 * np.real(r / np.sum(r)) # Make this eigenvector sum to one, then multiply by 100 Procrastinating Pats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from this list, the number of Ps that we expect to find on each website after long times.\n",
    "Putting them in order of *popularity* (based on this metric), the PageRank of this micro-internet is:\n",
    "\n",
    "**C**, **D**, **A**, **F**, **B**, **E**\n",
    "\n",
    "Referring back to the micro-internet diagram, is this what you would have expected?\n",
    "Convince yourself that based on which pages seem important given which others link to them, that this is a sensible ranking.\n",
    "\n",
    "Let's now try to get the same result using the Power-Iteration method that we covered in the class.\n",
    "This method will be much better at dealing with large systems.\n",
    "\n",
    "First let's set up our initial vector, $\\mathbf{r}^{(0)}$, so that we have our 100 Ps equally distributed on each of our 6 websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.66666667, 16.66666667, 16.66666667, 16.66666667, 16.66666667,\n",
       "       16.66666667])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = 100 * np.ones(6) / 6 # Sets up this vector (6 entries of 1/6 × 100 each)\n",
    "r # Shows it's value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's update the vector to the next minute, with the matrix $L$.\n",
    "Run the following cell multiple times, until the answer stabilises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.88888889, 13.88888889, 38.88888889, 27.77777778,  0.        ,\n",
       "        5.55555556])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = L @ r # Apply matrix L to r\n",
    "r # Show it's value\n",
    "# Re-run this cell multiple times to converge to the correct answer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can automate applying this matrix multiple times as follows,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.        ,  5.33333333, 40.        , 25.33333333,  0.        ,\n",
       "       13.33333333])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = 100 * np.ones(6) / 6 # Sets up this vector (6 entries of 1/6 × 100 each)\n",
    "for i in np.arange(100) : # Repeat 100 times\n",
    "    r = L @ r\n",
    "r"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or even better, we can keep running until we get to the required tolerance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 iterations to convergence.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([16.00149917,  5.33252025, 39.99916911, 25.3324738 ,  0.        ,\n",
       "       13.33433767])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = 100 * np.ones(6) / 6 # Sets up this vector (6 entries of 1/6 × 100 each)\n",
    "lastR = r\n",
    "r = L @ r\n",
    "i = 0\n",
    "while la.norm(lastR - r) > 0.01 :\n",
    "    lastR = r\n",
    "    r = L @ r\n",
    "    i += 1\n",
    "print(str(i) + \" iterations to convergence.\")\n",
    "r"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how the PageRank order is established fairly quickly, and the vector converges on the value we calculated earlier after a few tens of repeats."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Damping Parameter\n",
    "The system we just studied converged fairly quickly to the correct answer.\n",
    "Let's consider an extension to our micro-internet where things start to go wrong.\n",
    "\n",
    "Say a new website is added to the micro-internet: *G* Website.\n",
    "This website is linked to by *FaceSpace* and only links to itself.\n",
    "![An Expanded Micro-Internet](internet_2.png \"An Expanded Micro-Internet\")\n",
    "\n",
    "Intuitively, only *F*, which is in the bottom half of the page rank, links to this website amongst the two others it links to,\n",
    "so we might expect *G* site to have a correspondingly low PageRank score.\n",
    "\n",
    "Build the new $L$ matrix for the expanded micro-internet, and use Power-Iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    " # We'll call this one L2, to distinguish it from the previous L.\n",
    "L2 = np.array([[0,   1/2, 1/3,  0,  0,      0, 0],\n",
    "              [1/3,  0,   0,    0,  1/2,    0, 0],   \n",
    "              [1/3,  1/2, 0,    1,  0,    1/3, 0],\n",
    "              [1/3,  0,   1/3,  0,  1/2,  1/3, 0],\n",
    "              [0,    0,   0,    0,  0,      0, 0],\n",
    "              [0,    0,   1/3,  0,  0,      0, 0],\n",
    "              [0,    0,   0,    0,  0,    1/3, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 iterations to convergence.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.04699778e-02, 1.06432333e-02, 7.12661184e-02, 4.42319808e-02,\n",
       "       0.00000000e+00, 2.48934190e-02, 9.98184953e+01])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = 100 * np.ones(7) / 7 # Sets up this vector (6 entries of 1/6 × 100 each)\n",
    "lastR = r\n",
    "r = L2 @ r\n",
    "i = 0\n",
    "while la.norm(lastR - r) > 0.01 :\n",
    "    lastR = r\n",
    "    r = L2 @ r\n",
    "    i += 1\n",
    "print(str(i) + \" iterations to convergence.\")\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 0.5 # Feel free to play with this parameter after running the code once.\n",
    "M = d * L2 + (1-d)/7 * np.ones([7, 7]) # np.ones() is the J matrix, with ones for each entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 iterations to convergence.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([13.68217054, 11.20902965, 22.41964343, 16.7593433 ,  7.14285714,\n",
       "       10.87976354, 17.90719239])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = 100 * np.ones(7) / 7 # Sets up this vector (6 entries of 1/6 × 100 each)\n",
    "lastR = r\n",
    "r = M @ r\n",
    "i = 0\n",
    "while la.norm(lastR - r) > 0.01 :\n",
    "    lastR = r\n",
    "    r = M @ r\n",
    "    i += 1\n",
    "print(str(i) + \" iterations to convergence.\")\n",
    "r"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Produce a function that can calculate the PageRank for an arbitrarily large probability matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input link matrix L (which can be generated using the code given below) and damping factor d.\n",
    "def pageRank(L, d) :\n",
    "   \n",
    "    M = d * L + (1-d)/7 * np.ones([7, 7]) \n",
    "    r = 100 * np.ones(7) / 7 \n",
    "    lastR = r\n",
    "    r = M @ r\n",
    "    i = 0\n",
    "    while la.norm(lastR - r) > 0.01 :\n",
    "        lastR = r\n",
    "        r = M @ r\n",
    "        i += 1\n",
    "    print(str(i) + \" iterations to convergence.\")\n",
    "    \n",
    "    return r\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generatea random internet links\n",
    "def generate_link(n) :\n",
    "    c = np.full([n,n], np.arange(n))\n",
    "    c = (abs(np.random.standard_cauchy([n,n])/2) > (np.abs(c - c.T) + 1))+0\n",
    "    c = (c+1e-10) / np.sum((c+1e-10), axis=0)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0.5],\n",
       "       [0.5, 0.5]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the following function to generate internets of different sizes.\n",
    "generate_link(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your PageRank method against the built in \"eig\" method.\n",
    "L = generate_link(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 iterations to convergence.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([13.04445803,  8.69599524, 17.39088787, 23.18558944, 17.39088787,\n",
       "        8.69599524, 11.5961863 ])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pageRank(L, .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.54545455, 18.18181818,  4.54545455,  9.0909091 , 27.27272727,\n",
       "       15.15151515, 21.21212121])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using eigen vectors as seen before.\n",
    "eVals, eVecs = la.eig(L) # Gets the eigenvalues and vectors\n",
    "order = np.absolute(eVals).argsort()[::-1] # Orders them by their eigenvalues\n",
    "eVals = eVals[order]\n",
    "eVecs = eVecs[:,order]\n",
    "\n",
    "r = eVecs[:, 0]\n",
    "100 * np.real(r / np.sum(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answers do not match always. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Due to the fact that the eig method does not always converge the same value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
